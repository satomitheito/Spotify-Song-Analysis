{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Cleaning\n",
    "\n",
    "Data cleaning is a critical step in ensuring the quality and usability of data for analysis. In this project, the data cleaning process involved merging data frames, creating more-indepth columns, handling missing variables, and coverting data types.\n",
    "\n",
    "Since we want to analyze artists, songs, and lyrics, we conducted several changes such as adding song ranking, one hot encoding the genres, conducting sentiment analysis on the lyrics, and looking into artists features in a song. These will help streamline the EDA process as well as our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n",
    "Provide the source code used for this section of the project here.\n",
    "\n",
    "If you're using a package for code organization, you can import it at this point. However, make sure that the **actual workflow steps**—including data processing, analysis, and other key tasks—are conducted and clearly demonstrated on this page. The goal is to show the technical flow of your project, highlighting how the code is executed to achieve your results.\n",
    "\n",
    "If relevant, link to additional documentation or external references that explain any complex components. This section should give readers a clear view of how the project is implemented from a technical perspective.\n",
    "\n",
    "Remember, this page is a technical narrative, NOT just a notebook with a collection of code cells, include in-line Prose, to describe what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all the raw-data\n",
    "artists_data = pd.read_csv('../../data/raw-data/artists_data.csv')\n",
    "rolling_stone = pd.read_csv('../../data/raw-data/rolling_stone_top_100.csv')\n",
    "songs_lyrics = pd.read_csv('../../data/raw-data/songs_lyrics.csv')\n",
    "tracks_data = pd.read_csv('../../data/raw-data/tracks_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rolling_stone dataset has all the songs from rank 1-100 but tracks_data has two songs missing due to it not being found in the collection stage.\n",
    "#We are creating blank rows so that we can input the song rank column into the tracks_data\n",
    "empty_row = pd.Series(dtype='object') \n",
    "\n",
    "tracks_data = pd.concat(\n",
    "    [tracks_data.iloc[:72], empty_row.to_frame().T, tracks_data.iloc[72:]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "tracks_data = pd.concat(\n",
    "    [tracks_data.iloc[:74], empty_row.to_frame().T, tracks_data.iloc[74:]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "#We add the song rank into tracks_data\n",
    "tracks_data['Song Rank'] = range(1, 101)\n",
    "#Drop the empty columns as they will not be used. We just made them initially so that the ranking would not be wrong in tracks_data\n",
    "tracks_data = tracks_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "artists_data = artists_data.rename(columns={'Name': 'Artists'})\n",
    "tracks_data = tracks_data.rename(columns={'Popularity': 'Song Popularity'})\n",
    "tracks_data = tracks_data.rename(columns={'Release Date': 'Song Release Date'})\n",
    "tracks_data = tracks_data.rename(columns={'Artist': 'Artists'})\n",
    "artists_data = artists_data.rename(columns={'Release Date': 'Album Release Date'})\n",
    "\n",
    "#Merge column so we get artist and song info into one dataframe\n",
    "artists_tracks_data = pd.merge(tracks_data, artists_data, on='Artists', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to see how many artists were features on a song \n",
    "songs_lyrics['Total Artists On Song'] = songs_lyrics['Artists'].apply(lambda x: len(str(x).split('&')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the lyrics dataframe with the artist/song masterlist dataframe\n",
    "artists_tracks_data = pd.merge(artists_tracks_data, songs_lyrics, on='Track Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename and drop redundant columns\n",
    "artists_tracks_data = artists_tracks_data.drop(columns = ['Artists_y'])\n",
    "artists_tracks_data = artists_tracks_data.rename(columns={'Artists_x': 'Artists'})\n",
    "artists_tracks_data = artists_tracks_data.rename(columns={'lyrics': 'Lyrics'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the length of the lyrics \n",
    "artists_tracks_data['Lyrics Word Count'] = artists_tracks_data['Lyrics'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conducting sentimental analysis through VADER.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Created a function reads in the lyrics through VADER\n",
    "def analyze_sentiment(text):\n",
    "    sentiment = analyzer.polarity_scores(str(text))\n",
    "    return sentiment\n",
    "\n",
    "artists_tracks_data['Sentiment (VADER)'] = artists_tracks_data['Lyrics'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conducting TF-IDF on lyrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Initialize/tokenize \n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    #Remove english stop words\n",
    "    stop_words='english', \n",
    "    #We want to just look at single words \n",
    "    ngram_range=(1, 1)     \n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(artists_tracks_data['Lyrics'].fillna(''))\n",
    "\n",
    "#Convert TF-IDF into a dataframe\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    #Use TF-IDF feature as column headers\n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "    index=artists_tracks_data.index\n",
    ")\n",
    "tfidf_df.to_csv('../../data/processed-data/tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "artists_tracks_data['Genres'] = artists_tracks_data['Genres'].fillna('').astype(str)\n",
    "# plit genres into a list as there could be multiple generes in a single cell \n",
    "artists_tracks_data['Genres Split'] = artists_tracks_data['Genres'].apply(lambda x: [genre.strip() for genre in x.split(',')])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Fit the mlb to the split genres\n",
    "mlb.fit(artists_tracks_data['Genres Split'])\n",
    "\n",
    "#Create a list of column names based on the genres\n",
    "genre_columns = []\n",
    "for col in mlb.classes_:\n",
    "    genre_columns.append(f\"Genre_{col}\")\n",
    "\n",
    "#One hot encode on the seperated genres\n",
    "genre_one_hot = pd.DataFrame(\n",
    "    mlb.fit_transform(artists_tracks_data['Genres Split']),\n",
    "    columns=genre_columns,  \n",
    "    index=artists_tracks_data.index\n",
    ")\n",
    "\n",
    "#Concatenate one hot encoded columns into artists_tracks_data \n",
    "artists_tracks_data = pd.concat([artists_tracks_data, genre_one_hot], axis=1)\n",
    "artists_tracks_data = artists_tracks_data.drop(columns=['Genres Split'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_tracks_data.to_csv('../../data/processed-data/artist_song_masterlist.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
